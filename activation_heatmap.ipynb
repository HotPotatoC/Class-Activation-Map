{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xKyYmhooxFv",
        "colab_type": "text"
      },
      "source": [
        "# **Activation Heatmaps**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr6lyK4Dq2fN",
        "colab_type": "text"
      },
      "source": [
        "So in this notebook, we will make a Class Activation Map (CAM) on an image. But first, What is a Class Activation Map?\n",
        "\n",
        "take a look at the example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVEZlYuUrhjC",
        "colab_type": "text"
      },
      "source": [
        "![CAM Examples](https://raw.githubusercontent.com/anubhavmaity/Sports-Type-Classifier/master/readme_images/si_sports.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoNMnVrIrlat",
        "colab_type": "text"
      },
      "source": [
        "Class Activation Maps or **CAM**s are a great way to get the discriminative image regions used by a CNN (Convolutional Neural Network) to identify a specific class in an image. This is a useful technique for debugging and visualizing the contributing parts of the image to the model's prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB-_BnVosmQi",
        "colab_type": "text"
      },
      "source": [
        "# **Getting started**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoAW_HsstHEd",
        "colab_type": "text"
      },
      "source": [
        "## **Import the libraries**"
      ]
    },
    {
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mimg"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Using TensorFlow backend.\n"
        }
      ],
      "metadata": {},
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8zFEln86sil",
        "colab_type": "text"
      },
      "source": [
        "## **The image we will put the activation heatmap on**"
      ]
    },
    {
      "source": [
        "img_path = \"data/cat.jpg\"\n",
        "img = mimg.imread(img_path)\n",
        "plt.imshow(img)"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTcK0OdWAIsz",
        "colab_type": "text"
      },
      "source": [
        "## **Processing the image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEfTYK3uAOhL",
        "colab_type": "text"
      },
      "source": [
        "Now we will process the image by resizing it into a 224x224 image and then convert it into a numpy array"
      ]
    },
    {
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "def process_image(input_img):\n",
        "  img = image.load_img(input_img, target_size=(224, 224))\n",
        "  np_arr = image.img_to_array(img)\n",
        "  np_arr = np.expand_dims(np_arr, axis=0)\n",
        "  np_arr = preprocess_input(np_arr)\n",
        "  return np_arr\n",
        "\n",
        "img = process_image(img_path)\n",
        "img"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "source": [
        "img.shape"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNK1D1G_Na3R",
        "colab_type": "text"
      },
      "source": [
        "## **Using the VGG16 model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8W_4W29Nf7X",
        "colab_type": "text"
      },
      "source": [
        "Now we will be using a pre-trained model called VGG16. It refers to a deep convolutional network for object recognition developed and trained by Oxford's renown Visual Geometry Group (VGG)."
      ]
    },
    {
      "source": [
        "model = VGG16(weights='imagenet')\n",
        "model.summary()"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cmFRzfcS6eC",
        "colab_type": "text"
      },
      "source": [
        "## **Predicting**"
      ]
    },
    {
      "source": [
        "preds = model.predict(img)\n",
        "print('Predictions: ', decode_predictions(preds, top=5)[0])"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "source": [
        "np.argmax(preds[0])"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "source": [
        "predictions = pd.DataFrame(decode_predictions(preds)[0],columns=['col1','category','probability']).iloc[:,1:]\n",
        "print('Prediction:',predictions.loc[0,'category'])"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hhW7b1hVupr",
        "colab_type": "text"
      },
      "source": [
        "FYI: Tabby is a type of cat that is in the image, So the prediction went well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yynujK02Uacd",
        "colab_type": "text"
      },
      "source": [
        "## **Setting up the Grad-CAM**"
      ]
    },
    {
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def make_grad_cam(inputs):\n",
        "  np_argmax = np.argmax(preds[0])\n",
        "  output = model.output[:, np_argmax]\n",
        "  \n",
        "  # Get the last convolutional layer in our model\n",
        "  last_conv_layer = model.get_layer('block5_conv3')\n",
        "  \n",
        "  # Get the gradients of the outputs\n",
        "  gradients = K.gradients(output, last_conv_layer.output)[0]\n",
        "  pooled_grads = K.mean(gradients, axis=(0, 1, 2))\n",
        "\n",
        "  iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "  pooled_grads_value, conv_layer_output_value = iterate([inputs])\n",
        "  \n",
        "  for i in range(512):\n",
        "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "  heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "  return heatmap\n",
        "\n",
        "make_grad_cam(img)"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSoNlpF9bffc",
        "colab_type": "text"
      },
      "source": [
        "## **Setting up the Heatmap**"
      ]
    },
    {
      "source": [
        "def gen_heatmaps(image_input):\n",
        "  heatmap = make_grad_cam(image_input)\n",
        "  heatmap = np.maximum(heatmap, 0)\n",
        "  heatmap /= np.max(heatmap)\n",
        "  return heatmap\n",
        "\n",
        "generated_heatmap = gen_heatmaps(img)\n",
        "plt.matshow(generated_heatmap)"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCJb6fJecBUL",
        "colab_type": "text"
      },
      "source": [
        "Now, we've generated our heatmap congrats! You can see by the shape of the heatmap in the hottest region of the image, it resembles the cat's head shape. Now it's time to superimpose our heatmap with the original image. We will be using the `cv2` module to do the superimposition process of our heatmap to the original image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaX9upPGjHWB",
        "colab_type": "text"
      },
      "source": [
        "## **Superimposing Our Heatmap**"
      ]
    },
    {
      "source": [
        "from google.colab import files\n",
        "\n",
        "def superimpose_heatmap(image_input, hmap, intense_factor):\n",
        "  img = cv2.imread(image_input)\n",
        "\n",
        "  # Resizing the heatmap\n",
        "  heatmap = cv2.resize(hmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "  # Converting the heatmap values into rgb values\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "  # Applying a colormap to the heatmap, which in this notebook we will use COLORMAP_RAINBOW\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_RAINBOW)\n",
        "\n",
        "  superimposed_img = heatmap * intense_factor + img\n",
        "\n",
        "  # Saving the superimposed image\n",
        "  output = 'output/output.jpg'\n",
        "  cv2.imwrite(output, superimposed_img)\n",
        "\n",
        "  print(\"Finished generating image!\")\n",
        "  print(\"Output: \" + output)\n",
        "\n",
        "superimpose_heatmap(img_path, gen_heatmaps(img), 0.5)"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    }
  ]
}